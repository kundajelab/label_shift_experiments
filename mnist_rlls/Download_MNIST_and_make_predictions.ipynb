{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kundajelab/label_shift_experiments/blob/master/cifar10/Download_CIFAR10_models_from_zenodo_and_make_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version: 2.2.4\n",
      "tensorflow version: 1.14.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "print(\"keras version:\", keras.__version__)\n",
    "import tensorflow as tf\n",
    "print(\"tensorflow version:\", tf.__version__)\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 valid samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "full_x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "full_x_train /= 255\n",
    "x_test /= 255\n",
    "x_valid = full_x_train[-10000:]\n",
    "print('x_train shape:', full_x_train.shape)\n",
    "print(full_x_train.shape[0], 'train samples')\n",
    "print(x_valid.shape[0], 'valid samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "full_y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = full_y_train[-10000:]\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = \"test_labels.txt\"\n",
    "f = open(output_file, 'w')\n",
    "f.write(\"\\n\".join([\"\\t\".join([str(x) for x in y]) for y in y_test]))\n",
    "f.close()\n",
    "os.system(\"gzip -f \"+output_file)\n",
    "\n",
    "output_file = \"valid_labels.txt\"\n",
    "f = open(output_file, 'w')\n",
    "f.write(\"\\n\".join([\"\\t\".join([str(x) for x in y]) for y in y_valid]))\n",
    "f.close()\n",
    "os.system(\"gzip -f \"+output_file)\n",
    "\n",
    "output_file = \"train_labels.txt\"\n",
    "f = open(output_file, 'w')\n",
    "f.write(\"\\n\".join([\"\\t\".join([str(x) for x in y]) for y in full_y_train]))\n",
    "f.close()\n",
    "os.system(\"gzip -f \"+output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On train set size 30000\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 1.1742 - acc: 0.7175 - val_loss: 0.6226 - val_acc: 0.8657\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.5563 - acc: 0.8654 - val_loss: 0.4470 - val_acc: 0.8933\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.4487 - acc: 0.8852 - val_loss: 0.3881 - val_acc: 0.9009\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.4018 - acc: 0.8932 - val_loss: 0.3557 - val_acc: 0.9094\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3741 - acc: 0.8990 - val_loss: 0.3367 - val_acc: 0.9108\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3552 - acc: 0.9028 - val_loss: 0.3242 - val_acc: 0.9130\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 24us/step - loss: 0.3414 - acc: 0.9062 - val_loss: 0.3136 - val_acc: 0.9156\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3306 - acc: 0.9092 - val_loss: 0.3051 - val_acc: 0.9173\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3214 - acc: 0.9115 - val_loss: 0.2984 - val_acc: 0.9169\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3138 - acc: 0.9126 - val_loss: 0.2926 - val_acc: 0.9194\n",
      "Making predictions on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/amr1/miniconda3/envs/basepair/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"fl..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test set\n",
      "Test accuracy: 0.9178\n",
      "Valid accuracy: 0.9194\n",
      "Saving testpreacts_model_mnist_set-30000_seed-0.txt\n",
      "f0f52eca81d56c315628f9effb3dfbb0  testpreacts_model_mnist_set-30000_seed-0.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-0.txt\n",
      "f8b8c16e39c2dc3dc98f917d9828de7f  validpreacts_model_mnist_set-30000_seed-0.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 30us/step - loss: 1.1656 - acc: 0.7336 - val_loss: 0.6216 - val_acc: 0.8713\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.5498 - acc: 0.8703 - val_loss: 0.4456 - val_acc: 0.8940\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4429 - acc: 0.8881 - val_loss: 0.3855 - val_acc: 0.9018\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 24us/step - loss: 0.3964 - acc: 0.8962 - val_loss: 0.3539 - val_acc: 0.9070\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3690 - acc: 0.9017 - val_loss: 0.3346 - val_acc: 0.9114\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3502 - acc: 0.9057 - val_loss: 0.3205 - val_acc: 0.9140\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 24us/step - loss: 0.3361 - acc: 0.9087 - val_loss: 0.3094 - val_acc: 0.9158\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3248 - acc: 0.9109 - val_loss: 0.3017 - val_acc: 0.9181\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 24us/step - loss: 0.3155 - acc: 0.9139 - val_loss: 0.2946 - val_acc: 0.9201\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3077 - acc: 0.9159 - val_loss: 0.2886 - val_acc: 0.9210\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.9183\n",
      "Valid accuracy: 0.921\n",
      "Saving testpreacts_model_mnist_set-30000_seed-10.txt\n",
      "260be080ee3540ded634d773be845134  testpreacts_model_mnist_set-30000_seed-10.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-10.txt\n",
      "9c1619390d5a00b9b940eafbe7695356  validpreacts_model_mnist_set-30000_seed-10.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 34us/step - loss: 1.1828 - acc: 0.7143 - val_loss: 0.6320 - val_acc: 0.8631\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.5625 - acc: 0.8633 - val_loss: 0.4522 - val_acc: 0.8898\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.4527 - acc: 0.8831 - val_loss: 0.3905 - val_acc: 0.9013\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4046 - acc: 0.8932 - val_loss: 0.3582 - val_acc: 0.9059\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 24us/step - loss: 0.3758 - acc: 0.8988 - val_loss: 0.3396 - val_acc: 0.9097\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3564 - acc: 0.9036 - val_loss: 0.3244 - val_acc: 0.9122\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3419 - acc: 0.9070 - val_loss: 0.3133 - val_acc: 0.9155\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3305 - acc: 0.9099 - val_loss: 0.3050 - val_acc: 0.9171\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3210 - acc: 0.9118 - val_loss: 0.2979 - val_acc: 0.9183\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3130 - acc: 0.9140 - val_loss: 0.2918 - val_acc: 0.9192\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.918\n",
      "Valid accuracy: 0.9192\n",
      "Saving testpreacts_model_mnist_set-30000_seed-20.txt\n",
      "bf586c2636ed2c4727cc3505b85d12e5  testpreacts_model_mnist_set-30000_seed-20.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-20.txt\n",
      "2718805d70ab7ece95b5e1cfb987893c  validpreacts_model_mnist_set-30000_seed-20.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 33us/step - loss: 1.2099 - acc: 0.7147 - val_loss: 0.6378 - val_acc: 0.8682\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.5614 - acc: 0.8677 - val_loss: 0.4506 - val_acc: 0.8913\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.4488 - acc: 0.8865 - val_loss: 0.3878 - val_acc: 0.8999\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.4001 - acc: 0.8949 - val_loss: 0.3568 - val_acc: 0.9061\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3715 - acc: 0.9010 - val_loss: 0.3363 - val_acc: 0.9094\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3521 - acc: 0.9044 - val_loss: 0.3222 - val_acc: 0.9131\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3377 - acc: 0.9081 - val_loss: 0.3115 - val_acc: 0.9158\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3262 - acc: 0.9104 - val_loss: 0.3034 - val_acc: 0.9170\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3169 - acc: 0.9131 - val_loss: 0.2972 - val_acc: 0.9186\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3090 - acc: 0.9145 - val_loss: 0.2906 - val_acc: 0.9209\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.9181\n",
      "Valid accuracy: 0.9209\n",
      "Saving testpreacts_model_mnist_set-30000_seed-30.txt\n",
      "1432e16698c34f231e53aca497524da4  testpreacts_model_mnist_set-30000_seed-30.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-30.txt\n",
      "81f9001f7d0e90ecc692b42f3eabfa86  validpreacts_model_mnist_set-30000_seed-30.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 34us/step - loss: 1.1571 - acc: 0.7264 - val_loss: 0.6238 - val_acc: 0.8636\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.5570 - acc: 0.8623 - val_loss: 0.4497 - val_acc: 0.8880\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4503 - acc: 0.8827 - val_loss: 0.3905 - val_acc: 0.8994\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4038 - acc: 0.8917 - val_loss: 0.3599 - val_acc: 0.9057\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3760 - acc: 0.8984 - val_loss: 0.3404 - val_acc: 0.9086\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3574 - acc: 0.9026 - val_loss: 0.3264 - val_acc: 0.9120\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3432 - acc: 0.9059 - val_loss: 0.3178 - val_acc: 0.9143\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3323 - acc: 0.9090 - val_loss: 0.3077 - val_acc: 0.9167\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3234 - acc: 0.9119 - val_loss: 0.3006 - val_acc: 0.9176\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3158 - acc: 0.9132 - val_loss: 0.2953 - val_acc: 0.9203\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.9167\n",
      "Valid accuracy: 0.9203\n",
      "Saving testpreacts_model_mnist_set-30000_seed-40.txt\n",
      "232078a3be3dd38a43d967672fb7dd2b  testpreacts_model_mnist_set-30000_seed-40.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-40.txt\n",
      "07f6f7ced1dfddb9055f6e5883d5cf36  validpreacts_model_mnist_set-30000_seed-40.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 36us/step - loss: 1.1192 - acc: 0.7434 - val_loss: 0.6134 - val_acc: 0.8694\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.5502 - acc: 0.8659 - val_loss: 0.4460 - val_acc: 0.8920\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4464 - acc: 0.8840 - val_loss: 0.3875 - val_acc: 0.9012\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3992 - acc: 0.8937 - val_loss: 0.3572 - val_acc: 0.9065\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3713 - acc: 0.9004 - val_loss: 0.3361 - val_acc: 0.9118\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3521 - acc: 0.9038 - val_loss: 0.3231 - val_acc: 0.9137\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3375 - acc: 0.9079 - val_loss: 0.3117 - val_acc: 0.9167\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3259 - acc: 0.9107 - val_loss: 0.3030 - val_acc: 0.9171\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3165 - acc: 0.9126 - val_loss: 0.2963 - val_acc: 0.9187\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3087 - acc: 0.9151 - val_loss: 0.2900 - val_acc: 0.9200\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.9167\n",
      "Valid accuracy: 0.92\n",
      "Saving testpreacts_model_mnist_set-30000_seed-50.txt\n",
      "071a68e9a11eb7388f54fedabb8af47a  testpreacts_model_mnist_set-30000_seed-50.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-50.txt\n",
      "f2fb73c24a2c43aac354be2161968422  validpreacts_model_mnist_set-30000_seed-50.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 1.1516 - acc: 0.7345 - val_loss: 0.6133 - val_acc: 0.8682\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.5463 - acc: 0.8688 - val_loss: 0.4432 - val_acc: 0.8909\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4418 - acc: 0.8865 - val_loss: 0.3852 - val_acc: 0.8994\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3955 - acc: 0.8956 - val_loss: 0.3542 - val_acc: 0.9061\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3682 - acc: 0.9017 - val_loss: 0.3350 - val_acc: 0.9100\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3493 - acc: 0.9060 - val_loss: 0.3216 - val_acc: 0.9133\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3351 - acc: 0.9094 - val_loss: 0.3103 - val_acc: 0.9160\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3242 - acc: 0.9110 - val_loss: 0.3028 - val_acc: 0.9173\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3151 - acc: 0.9135 - val_loss: 0.2960 - val_acc: 0.9189\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3075 - acc: 0.9155 - val_loss: 0.2899 - val_acc: 0.9195\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.9182\n",
      "Valid accuracy: 0.9195\n",
      "Saving testpreacts_model_mnist_set-30000_seed-60.txt\n",
      "e88f6b8b1e711ce76b303ef202a7ee94  testpreacts_model_mnist_set-30000_seed-60.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-60.txt\n",
      "b278c9c9da926a8b54c3a8a033ddad45  validpreacts_model_mnist_set-30000_seed-60.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 1.1595 - acc: 0.7385 - val_loss: 0.6254 - val_acc: 0.8720\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.5535 - acc: 0.8679 - val_loss: 0.4480 - val_acc: 0.8927\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4465 - acc: 0.8846 - val_loss: 0.3892 - val_acc: 0.8996\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3998 - acc: 0.8941 - val_loss: 0.3581 - val_acc: 0.9051\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 24us/step - loss: 0.3721 - acc: 0.8997 - val_loss: 0.3383 - val_acc: 0.9090\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3532 - acc: 0.9042 - val_loss: 0.3245 - val_acc: 0.9125\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3389 - acc: 0.9073 - val_loss: 0.3150 - val_acc: 0.9141\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3280 - acc: 0.9099 - val_loss: 0.3062 - val_acc: 0.9146\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3186 - acc: 0.9117 - val_loss: 0.2991 - val_acc: 0.9163\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3111 - acc: 0.9144 - val_loss: 0.2941 - val_acc: 0.9182\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.9168\n",
      "Valid accuracy: 0.9182\n",
      "Saving testpreacts_model_mnist_set-30000_seed-70.txt\n",
      "701dd72ed9a99076e3428e5bd73cd29d  testpreacts_model_mnist_set-30000_seed-70.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-70.txt\n",
      "c163e6153430ca9e24813308f53b45fa  validpreacts_model_mnist_set-30000_seed-70.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 38us/step - loss: 1.1987 - acc: 0.7223 - val_loss: 0.6414 - val_acc: 0.8644\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.5650 - acc: 0.8657 - val_loss: 0.4546 - val_acc: 0.8884\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4525 - acc: 0.8838 - val_loss: 0.3911 - val_acc: 0.9004\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4033 - acc: 0.8923 - val_loss: 0.3584 - val_acc: 0.9055\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3741 - acc: 0.8994 - val_loss: 0.3377 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3542 - acc: 0.9036 - val_loss: 0.3234 - val_acc: 0.9130\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3395 - acc: 0.9078 - val_loss: 0.3115 - val_acc: 0.9154\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3278 - acc: 0.9099 - val_loss: 0.3023 - val_acc: 0.9174\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3181 - acc: 0.9130 - val_loss: 0.2962 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3102 - acc: 0.9153 - val_loss: 0.2891 - val_acc: 0.9201\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.918\n",
      "Valid accuracy: 0.9201\n",
      "Saving testpreacts_model_mnist_set-30000_seed-80.txt\n",
      "b4fbf67adcce57b92f32cfeb8fbd2197  testpreacts_model_mnist_set-30000_seed-80.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-80.txt\n",
      "e95d92082bb3ef6afadca58759bd36bd  validpreacts_model_mnist_set-30000_seed-80.txt\n",
      "On train set size 30000\n",
      "Mean y train: [0.0987     0.1141     0.09826667 0.10243333 0.09753333 0.0903\n",
      " 0.09916667 0.10356667 0.09583333 0.1001    ]\n",
      "Mean y valid: [0.0991 0.1064 0.099  0.103  0.0983 0.0915 0.0967 0.109  0.1009 0.0961]\n",
      "Train on 30000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 1s 42us/step - loss: 1.1638 - acc: 0.7276 - val_loss: 0.6319 - val_acc: 0.8621\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.5602 - acc: 0.8641 - val_loss: 0.4535 - val_acc: 0.8906\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.4516 - acc: 0.8836 - val_loss: 0.3929 - val_acc: 0.9016\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.4036 - acc: 0.8925 - val_loss: 0.3611 - val_acc: 0.9066\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3754 - acc: 0.8990 - val_loss: 0.3421 - val_acc: 0.9109\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3562 - acc: 0.9029 - val_loss: 0.3278 - val_acc: 0.9126\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3420 - acc: 0.9057 - val_loss: 0.3173 - val_acc: 0.9142\n",
      "Epoch 8/10\n",
      "30000/30000 [==============================] - 1s 22us/step - loss: 0.3309 - acc: 0.9083 - val_loss: 0.3084 - val_acc: 0.9167\n",
      "Epoch 9/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3217 - acc: 0.9110 - val_loss: 0.3017 - val_acc: 0.9174\n",
      "Epoch 10/10\n",
      "30000/30000 [==============================] - 1s 23us/step - loss: 0.3140 - acc: 0.9134 - val_loss: 0.2969 - val_acc: 0.9192\n",
      "Making predictions on validation set\n",
      "Making predictions on test set\n",
      "Test accuracy: 0.9159\n",
      "Valid accuracy: 0.9192\n",
      "Saving testpreacts_model_mnist_set-30000_seed-90.txt\n",
      "47fea0b166d23f8dcb30e9fa363960e6  testpreacts_model_mnist_set-30000_seed-90.txt\n",
      "Saving validpreacts_model_mnist_set-30000_seed-90.txt\n",
      "a3856050266c8bbc06b4dbc2d74b5c20  validpreacts_model_mnist_set-30000_seed-90.txt\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "model_files = []\n",
    "for seed in range(0,100,10):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    for model_idx,train_set_size in enumerate([30000]):\n",
    "        model_file = \"model_mnist_set-\"+str(train_set_size)+\"_seed-\"+str(seed)+\".h5\"\n",
    "        model_files.append(model_file)\n",
    "        print(\"On train set size\",train_set_size)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=input_shape))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(num_classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        optimizer = optimizers.SGD(lr=0.01, momentum=0.5, decay=5e-4)\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "        x_train = full_x_train[:train_set_size] \n",
    "        y_train = full_y_train[:train_set_size]\n",
    "        print(\"Mean y train:\",np.mean(y_train, axis=0))\n",
    "        print(\"Mean y valid:\",np.mean(y_valid, axis=0))\n",
    "        model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=1,\n",
    "                  validation_data=(x_valid, y_valid),\n",
    "                  callbacks=[EarlyStopping(\n",
    "                    monitor='val_loss', patience=10,\n",
    "                    restore_best_weights=True)])\n",
    "        model.save(model_file)\n",
    "\n",
    "        pre_softmax_model = Model(input=model.input,\n",
    "                            output=model.layers[-2].output)\n",
    "        print(\"Making predictions on validation set\")\n",
    "        valid_preacts = pre_softmax_model.predict(x_valid)\n",
    "        print(\"Making predictions on test set\")\n",
    "        test_preacts = pre_softmax_model.predict(x_test)\n",
    "        print('Test accuracy:', np.mean(np.argmax(test_preacts,axis=-1)\n",
    "                                        ==np.argmax(y_test,axis=-1)))\n",
    "        print('Valid accuracy:', np.mean(np.argmax(valid_preacts,axis=-1)\n",
    "                                        ==np.argmax(y_valid,axis=-1)))\n",
    "        sys.stdout.flush()\n",
    "        test_predictions_file = (\"testpreacts_\"+model_file.split(\".\")[0])+\".txt\"\n",
    "        print(\"Saving\", test_predictions_file)\n",
    "        f = open(test_predictions_file,'w')\n",
    "        for test_preact in test_preacts:\n",
    "            f.write(\"\\t\".join([str(x) for x in test_preact])+\"\\n\") \n",
    "        f.close()\n",
    "        !md5sum $test_predictions_file\n",
    "        !gzip $test_predictions_file\n",
    "\n",
    "        valid_predictions_file = (\"validpreacts_\"+model_file.split(\".\")[0])+\".txt\"\n",
    "        print(\"Saving\", valid_predictions_file)\n",
    "        f = open(valid_predictions_file,'w')\n",
    "        for valid_preact in valid_preacts:\n",
    "            f.write(\"\\t\".join([str(x) for x in valid_preact])+\"\\n\") \n",
    "        f.close()\n",
    "        !md5sum $valid_predictions_file\n",
    "        !gzip $valid_predictions_file"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "gist - Download CIFAR10 models from zenodo and make predictions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:basepair]",
   "language": "python",
   "name": "conda-env-basepair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
